{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39415dad",
   "metadata": {},
   "source": [
    "# GABRIEL Library Stress Test\n",
    "\n",
    "This notebook exercises various API calls and pipelines using real OpenAI responses. Ensure you have API access before running. All calls set `use_dummy=False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e35f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, shutil, asyncio, pandas as pd\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "from gabriel.utils import openai_utils\n",
    "from gabriel.tasks import (\n",
    "    Ratings, RatingsConfig,\n",
    "    BasicClassifier, BasicClassifierConfig,\n",
    "    Deidentifier, DeidentifyConfig,\n",
    "    Regional, RegionalConfig,\n",
    "    CountyCounter,\n",
    "    EloRater, EloConfig,\n",
    "    RecursiveEloConfig, RecursiveEloRater,\n",
    ")\n",
    "from gabriel.utils import Teleprompter, PromptParaphraser, PromptParaphraserConfig\n",
    "\n",
    "out_dir = 'stress_test_outputs'\n",
    "if os.path.exists(out_dir):\n",
    "    shutil.rmtree(out_dir)\n",
    "os.makedirs(out_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\ntry:\n    from sklearn.datasets import fetch_20newsgroups\n    ng = fetch_20newsgroups(subset='train', categories=['sci.space'], remove=('headers','footers','quotes'), download_if_missing=False)\n    sample_texts = ng.data[:8]\nexcept Exception:\n    sample_texts = [\n        'Space exploration has entered a new golden age with private companies.',\n        'Astronomers recently discovered water on a distant exoplanet.',\n        'Rockets are becoming reusable thanks to modern engineering.',\n        'Satellite technology enables global internet coverage.',\n        'Mars missions are planned for the next decade.',\n        'The International Space Station hosts numerous experiments.',\n        'Studying cosmic radiation helps us understand the universe.',\n        'Observatories around the world capture images of distant galaxies.',\n    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\nng_df = await openai_utils.get_all_responses(\n    prompts=sample_texts,\n    identifiers=[f'ng{i}' for i in range(1, len(sample_texts)+1)],\n    use_dummy=False,\n    save_path=os.path.join(out_dir,'ng.csv')\n)\nng_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff850e82",
   "metadata": {},
   "source": [
    "## Basic `get_all_responses`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\nprompts = [\n    'Summarize the plot of Hamlet in two sentences.',\n    'Explain the theory of general relativity in simple terms.',\n    'Describe how photosynthesis works.',\n    'Give three reasons why exercise is beneficial.',\n    'Outline the history of the Internet.',\n    'What causes thunderstorms to form?',\n    'Provide a short biography of Ada Lovelace.',\n    'How does blockchain technology maintain security?',\n    'List important features of a democratic government.',\n    'Why is biodiversity important for ecosystems?'\n]\ndf = await openai_utils.get_all_responses(\n    prompts=prompts,\n    identifiers=[f'p{i}' for i in range(1, len(prompts)+1)],\n    use_dummy=False,\n    save_path=os.path.join(out_dir,'basic.csv')\n)\ndf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16edcbda",
   "metadata": {},
   "source": [
    "## JSON mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffb321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\njson_prompts = [\n    'Create a JSON object with keys \"name\", \"age\", and \"city\" for a fictional person named Alice who is 30 and lives in Denver.',\n    'Provide JSON describing a product with fields \"id\", \"description\", and \"price\" for a laptop that costs 999.'\n]\nschema = {\"type\": \"object\"}\njson_df = await openai_utils.get_all_responses(\n    prompts=json_prompts,\n    json_mode=True,\n    expected_schema=schema,\n    use_dummy=False,\n    save_path=os.path.join(out_dir,'json.csv')\n)\njson_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e706606",
   "metadata": {},
   "source": [
    "## Web search tool usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d025ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\nsearch_prompts = [\n    'What is the tallest mountain in Africa and who led the first recorded ascent?'\n]\nweb_df = await openai_utils.get_all_responses(\n    prompts=search_prompts,\n    identifiers=['search1'],\n    use_web_search=True,\n    use_dummy=False,\n    save_path=os.path.join(out_dir,'web.csv')\n)\nweb_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5299f5",
   "metadata": {},
   "source": [
    "## Resume from existing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05872a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\nresume_prompts = [\n    'Define artificial intelligence.',\n    'What are neural networks used for?',\n    'Explain the Turing test.',\n    'Describe the concept of machine learning.',\n    'List applications of computer vision.'\n]\n# First run with only three prompts\n_ = await openai_utils.get_all_responses(\n    prompts=resume_prompts[:3],\n    identifiers=[f'r{i}' for i in range(1,4)],\n    use_dummy=False,\n    save_path=os.path.join(out_dir,'resume.csv')\n)\n# Second run with all prompts (should only process remaining ones)\nresume_df = await openai_utils.get_all_responses(\n    prompts=resume_prompts,\n    identifiers=[f'r{i}' for i in range(1,6)],\n    use_dummy=False,\n    save_path=os.path.join(out_dir,'resume.csv')\n)\nresume_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19995ae0",
   "metadata": {},
   "source": [
    "## Ratings pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2a3878",
   "metadata": {},
   "outputs": [],
   "source": [
    "\ndata = pd.DataFrame({'text': [\n    'The new smartphone release offers cutting-edge features and sleek design.',\n    'Customer support was unhelpful and slow to respond.'\n]})\nratings_cfg = RatingsConfig(\n    attributes={\n        'clarity': 'Is the text easy to understand?',\n        'detail': 'Does the text provide sufficient detail?',\n        'tone': 'Assess the overall tone.'\n    },\n    save_dir=os.path.join(out_dir,'ratings'),\n    use_dummy=False\n)\nratings_res = await Ratings(ratings_cfg).run(data, text_column='text')\nratings_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3678419d",
   "metadata": {},
   "source": [
    "## BasicClassifier pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc292dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\nclf_data = pd.DataFrame({'txt': [\n    'I absolutely loved the new movie!',\n    'The service at the restaurant was terrible.',\n    'It was an average experience overall.'\n]})\nclf_cfg = BasicClassifierConfig(\n    labels={\n        'positive': 'Is the sentiment positive?',\n        'negative': 'Is the sentiment negative?',\n        'neutral': 'Is the sentiment neutral?'\n    },\n    save_dir=os.path.join(out_dir,'classifier'),\n    use_dummy=False\n)\nclf_res = await BasicClassifier(clf_cfg).run(clf_data, text_column='txt')\nclf_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d3574",
   "metadata": {},
   "source": [
    "## Deidentifier pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "\ndeid_data = pd.DataFrame({'text': [\n    'Jane Doe met with Dr. Smith in New York on July 4th, 2021.',\n    'Contact me at 555-123-4567 or email john@example.com.'\n]})\ndeid_cfg = DeidentifyConfig(\n    save_path=os.path.join(out_dir,'deid.csv'),\n    use_dummy=False\n)\ndeid_res = await Deidentifier(deid_cfg).run(deid_data, text_column='text')\ndeid_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060f2a56",
   "metadata": {},
   "source": [
    "## Regional analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9227cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\nreg_data = pd.DataFrame({'county': ['A', 'B', 'C']})\nreg_cfg = RegionalConfig(\n    save_dir=os.path.join(out_dir,'regional'),\n    use_dummy=False\n)\nregional_task = Regional(reg_data, 'county', topics=['economy', 'public safety'], cfg=reg_cfg)\nregional_res = await regional_task.run()\nregional_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c9172",
   "metadata": {},
   "source": [
    "## CountyCounter pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109dc797",
   "metadata": {},
   "outputs": [],
   "source": [
    "\ncounty_data = pd.DataFrame({\n    'county': ['A', 'B', 'C'],\n    'fips': ['00001', '00002', '00003']\n})\ncc = CountyCounter(\n    county_data,\n    county_col='county',\n    topics=['econ', 'health'],\n    fips_col='fips',\n    save_dir=os.path.join(out_dir,'county'),\n    use_dummy=False,\n    n_elo_rounds=1\n)\ncounty_res = await cc.run()\ncounty_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298b8aff",
   "metadata": {},
   "source": [
    "## EloRater pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d35971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\nelo_data = pd.DataFrame({'identifier':['x','y'], 'text':['Text X with clear explanation','Text Y with vague content']})\ntele = Teleprompter()\nelo_cfg = EloConfig(\n    attributes={'clarity':'', 'informativeness':''},\n    n_rounds=2,\n    save_dir=os.path.join(out_dir,'elo'),\n    use_dummy=False\n)\nelo_task = EloRater(tele, elo_cfg)\nelo_res = await elo_task.run(elo_data, text_col='text', id_col='identifier')\nelo_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8a7fd",
   "metadata": {},
   "source": [
    "## RecursiveEloRater pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\nrec_data = pd.DataFrame({'identifier':['a','b','c','d'], 'text':['Alpha text','Bravo text','Charlie text','Delta text']})\nbase_cfg = EloConfig(\n    attributes={'score':''},\n    n_rounds=1,\n    save_dir=os.path.join(out_dir,'rec'),\n    use_dummy=False\n)\nrec_cfg = RecursiveEloConfig(base_cfg=base_cfg, min_remaining=2)\nrec_task = RecursiveEloRater(tele, rec_cfg)\nrec_res = await rec_task.run(rec_data, text_col='text', id_col='identifier')\nrec_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\nfrom gabriel.utils.parsing import safest_json\nfrom unittest.mock import patch\n\nasync def fake_response(*args, **kwargs):\n    return ['{\"good\": true}'], 0.0\n\nwith patch('gabriel.utils.openai_utils.get_response', fake_response):\n    fixed_json = await safest_json('{bad:1}')\nfixed_json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1a8d05",
   "metadata": {},
   "source": [
    "## PromptParaphraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\nbatch_prompts = [f'Batch prompt {i}' for i in range(1,9)]\nbatch_df = await openai_utils.get_all_responses(\n    prompts=batch_prompts,\n    identifiers=[f'b{i}' for i in range(1,9)],\n    use_batch=True,\n    use_dummy=False,\n    save_path=os.path.join(out_dir,'batch.csv'),\n)\nbatch_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa9cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\nparap_cfg = PromptParaphraserConfig(\n    n_variants=3,\n    save_dir=os.path.join(out_dir,'parap'),\n    use_dummy=False\n)\nparap = PromptParaphraser(parap_cfg)\nparap_res = await parap.run(Ratings, ratings_cfg, data, text_column='text')\nparap_res\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}